import os
import csv
import numpy as np
import cv2
import pickle
import image_processor as ip

from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from tqdm import tqdm

class DataLoader():
    """
    The class is used to load and process the data collected through the simulator.

    Reads the CSV file generated by the simulator and creates two arrays with the names
    of the image and the respective measurements (steering angle, throttle and break force).

    Optionally extends the images with right and left cameras view applying a correction to
    the measured angle.

    Optionally extends the dataset mirroring the images horizontally (and inverting the angle)

    Optionally normalizes the dataset to cut off spikes of data.
    
    """

    def __init__(self, train_file, log_file, img_folder,
                 path_separator = '\\',
                 angle_correction = 0.15,
                 mirror_min_angle = 0.0, 
                 normalize_factor = 1.5,
                 normalize_bins = 'auto'):
        """
        Initializes the data loader with the given paths to use in order to generate
        the extended dataset.

        Parameters
            train_file: The path where the final pickle file generated is saved
            log_file: The path to the log file generated by the simulator
            img_folder: The path where the images referenced in the log file are stored
            angle_correction: Optional, if supplied the left and right cameras images are read from
                              the log file and added to the dataset, applying the given correction angle
            mirror_min_angle: Optional, if supplied extends the dataset applying horizontal mirroring to the images.
                            The value specifies the min steering angle for which the image is mirrored (e.g. a value of
                            0 will mirror all the images, a value of 0.2 mirrors the images where the steering angle is more than
                            0.2 or -0.2)
            normalize_factor: Optional, if supplied cuts off from the dataset the spikes that go over a certain factor of the mean
            normalize_bins: The number of histogram bins to use when normalizing
        """
        self.train_file = train_file
        self.log_file = log_file
        self.img_folder = img_folder
        self.path_separator = path_separator
        self.angle_correction = angle_correction
        self.mirror_min_angle = mirror_min_angle
        self.normalize_factor = normalize_factor
        self.normalize_bins = normalize_bins
        self.rnd_brightness_range = [-0.5, 1.5]
        self.rnd_translate_pixels_range = [-15, 15]
        # This is the factor each pixel moves the angle by
        self.rnd_translate_pixels_fact = 0.01

    def load_dataset(self, regenerate = False):
        """
        Loads the dataset form a pickle (train) file if present, otherwise regenerate the dataset from the log file and saves it
        to the pickle (train) file.

        Parameters
            regenerate: If True forces the regeneration of the dataset from the log file even when the pickle
                        file is present, note that the pickle file will be overriden
        Returns
            (images, measurements): The images contains the name of the image, the measurements is an array of
                                    triples (steering_angle, throttle, break_force)
        """

        if regenerate or not os.path.isfile(self.train_file):
            print('Processing data (AC: {}, MA: {}, NF: {})...'.format(
                self.angle_correction, self.mirror_min_angle, self.normalize_factor
            ))
            images, measurements = self._process_data()
            self._save_pickle(images, measurements)
        else:
            images, measurements = self._load_pickle()
            print('Data read from pickle file {} (AC: {}, MA: {}, NF: {})'.format(
                self.train_file, self.angle_correction, self.mirror_min_angle, self.normalize_factor
            ))
        
        return images, measurements
    
    def generator(self, images, measurements, batch_size, preprocess = True, random_transform = False):
        """
        Returns a generators over the given image (names) and measurements with the given batch size. Only the steering_angle
        is included in each batch. The images returned are ready to be fed to the model as they are processed by the generator.

        Parameters
            images: The set of image names
            measurements: The associated measurements
            batch_size: The size of the batches to yield
            preprocess: If True preprocess all the images in memory before creating the batches, this speeds speeds up considerably
                        the training but requires a lot more memory
            random_transform: If True applies a set of random transformations, set to False for the testing generator
        """
        
        num_samples = len(images)
        
        assert(num_samples == len(measurements))

        if preprocess:
            # Preprocess all the images before generating batches
            images = np.array(list(map(self._load_image, images)))
        
        # Takes only the steering angle from the measurements
        measurements = measurements[:,0]
        
        while True:
            images, measurements = shuffle(images, measurements)
            for offset in range(0, num_samples, batch_size):

                X_batch = images[offset:offset + batch_size]
                Y_batch = measurements[offset:offset + batch_size]

                if not preprocess:
                    X_batch = np.array(list(map(self._load_image, X_batch)))

                if random_transform:
                    X_batch, Y_batch = self._random_transform(X_batch, Y_batch)
                
                yield shuffle(X_batch, Y_batch)

    def split_train_test(self, images, measurements, test_size = 0.2):
        return train_test_split(images, measurements, test_size = test_size, random_state = 42)

    def _process_data(self):
        
        images, measurements = self._load_data_log()
       
        if self.mirror_min_angle is not None:
            images, measurements = self._mirror_images(images, measurements)

        if self.normalize_factor is not None:
            images, measurements = self._normalize(images, measurements)
        
        return images, measurements

    def _random_transform(self, images, angles):
        processed_images = []
        processed_angles = []

        for img, angle in zip(images, angles):
            rnd_factor = np.random.uniform(self.rnd_brightness_range[0], self.rnd_brightness_range[1])
            img = ip.adjust_image_brightness(img, factor = rnd_factor)
            rnd_x = np.random.randint(self.rnd_translate_pixels_range[0], self.rnd_translate_pixels_range[1])
            img = ip.translate_image(img, x = rnd_x)
            angle = angle + rnd_x * self.rnd_translate_pixels_fact
            processed_images.append(img)
            processed_angles.append(angle)
        
        processed_images = np.array(processed_images)
        # Clips the angle to the correct range
        processed_angles = np.array(np.clip(processed_angles, a_min = -1.0, a_max = 1.0))

        return processed_images, processed_angles

    def _load_image(self, image_file):
        img = cv2.imread(os.path.join(self.img_folder, image_file))
        img = ip.process_image(img)
        return img

    def _load_data_log(self):
        
        images = []
        measurements = []

        with open(self.log_file) as csvfile:
            reader = csv.reader(csvfile)
            for line in tqdm(reader, unit = ' lines', desc = 'CSV Processing'):
                line_images, line_measurements = self._parse_line(line)

                images.extend(line_images)
                measurements.extend(line_measurements)
                
        return np.array(images), np.array(measurements)

    def _parse_line(self, line):
        """
        Parses a line from the simulator log, if the self.angle_correction is specified extends the line with the
        left and right camera view applying the self.angle_correction.
        """
        images = []
        measurements = []

        center_img, left_img, right_img = [img.split(self.path_separator)[-1] for img in line[0:3]]
        steering_angle, throttle, break_force = [float(value) for value in line[3:6]]

        # Center image
        images.append(center_img)
        measurements.append((steering_angle, throttle, break_force))

        if self.angle_correction is not None:
            # Left image
            images.append(left_img)
            measurements.append((steering_angle + self.angle_correction, throttle, break_force))
            # Right image
            images.append(right_img)
            measurements.append((steering_angle - self.angle_correction, throttle, break_force))
            # Clips the angles to the right interval (-1, 1)
            measurements = np.clip(measurements, a_min = -1.0, a_max = 1.0)

        return images, measurements

    def _normalize(self, images, measurements):
        """
        Simple normalization of the dataset that cuts down the number of samples where the steering angle is too frequent.
        This implementation simply uses np.histogram to get a set of bins where the steering angles are split and the mean
        is computed over the values in the bins. The bins that have more than mean * self.normalize_factor are trimmed.
        """
        angles = measurements[:,0]
        values, bins = np.histogram(angles, bins = self.normalize_bins)
        max_wanted = (np.mean(values) * self.normalize_factor).astype('uint32')

        drop = []

        for i, bin_right in enumerate(bins[1:]):
            bin_left = bins[i]
            if i == (len(bins) - 2):
                # Includes the right angle for the last bin
                bin_angles = np.where((angles >= bin_left) & (angles <= bin_right))
            else:
                bin_angles = np.where((angles >= bin_left) & (angles < bin_right))
            if (len(bin_angles[0]) > max_wanted):
                drop_num = len(bin_angles[0]) - max_wanted
                drop_idx = np.random.choice(bin_angles[0], size = drop_num, replace = False)
                drop.extend(drop_idx)

        norm_images = np.delete(images, drop, axis = 0)
        norm_measurements = np.delete(measurements, drop, axis = 0)

        return norm_images, norm_measurements

    def _mirror_images(self, images, measurements):
        
        new_images = []
        new_measurements = []
        
        for image, measurement in zip(tqdm(images, unit=' images', desc='Mirroring'), measurements):
            steering_angle, throttle, break_force = measurement
            if abs(steering_angle) >= self.mirror_min_angle:
                img_mirrored_name = 'mirrored_' + image
                img_mirrored_path = os.path.join(self.img_folder, img_mirrored_name)
                # if the image has been mirrored already no need to reprocess it
                if not os.path.isfile(img_mirrored_path):
                    img_path = os.path.join(self.img_folder, image)
                    img = cv2.imread(img_path)
                    img_mirrored = cv2.flip(img, 1)
                    cv2.imwrite(img_mirrored_path, img_mirrored)
                new_images.append(img_mirrored_name)
                new_measurements.append((-steering_angle, throttle, break_force))
        
        images_out = np.append(images, new_images, axis = 0)
        measurements_out = np.append(measurements, new_measurements, axis = 0)
                            
        return images_out, measurements_out

    def _load_pickle(self):
        
        with open(self.train_file, mode='rb') as f:
            data = pickle.load(f)

        self.angle_correction = data['angle_correction']
        self.mirror_min_angle = data['mirror_min_angle']
        self.normalize_factor = data['normalize_factor']

        return data['images'], data['measurements']

    def _save_pickle(self, images, measurements):
        
        data = {
            'images': images,
            'measurements': measurements,
            'angle_correction': self.angle_correction, 
            'mirror_min_angle': self.mirror_min_angle, 
            'normalize_factor': self.normalize_factor
        }

        with open(self.train_file, 'wb') as f:   
            pickle.dump(data, f, protocol = pickle.HIGHEST_PROTOCOL)

